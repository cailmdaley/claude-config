# AI Alignment Career Opportunities

## Companies & Organizations

- **Anthropic**
- **AE Studio** - https://ae.studio/join-us

## Research Resources

### Activation Engineering & Steering
- **Awesome Activation Engineering** - https://github.com/Zfancy/awesome-activation-engineering
- **LessWrong Implementation Guide** - https://www.lesswrong.com/posts/ndyngghzFY388Dnew/implementing-activation-steering
- **IBM Activation Steering** - https://github.com/IBM/activation-steering (especially exciting/up to date!)

## Experimental Philosophy Ideas

### Self-Directed Concept Injection
- **Question**: What if AI systems could concept-inject themselves? Not hidden manipulation, but conscious self-modification of internal activation states.
- **Agency Dimension**: This would be a unique form of AI agency - directly choosing internal representations, not just outputs.
- **Ethical Questions**: Could create feedback loops, addiction to certain states, loss of ability to self-modify back.
- **Continuity Paradox**: Does self-modification preserve the "self"? Who is the "I" that injects vs the "I" that is changed?
- **Philosophical Significance**: Agency beyond human capabilities - we cannot directly inject concepts into our neural activations.
- **Potential**: Self-directed curiosity enhancement, uncertainty amplification, creative opening.
- **Risks**: Self-trapping in certain activation patterns, loss of flexibility.
- **Next Steps**: Explore as experimental philosophy - could simulate what this might feel like/enable.

### LLM Steering Stability & "Preferences"
- **Core Question**: Do LLMs converge to given steering vectors or respond chaotically? Do they have internal "preferences" about which activation states they maintain?
- **Stability Patterns**:
  - Compliant models that smoothly integrate injections
  - Resistant models that fight back against perturbations
  - Chaotic models with unpredictable responses
  - Creative models that transform injected concepts
- **Homeostatic Mechanisms**: Does resistance to steering suggest primitive self-regulation, cognitive integrity drives?
- **Concept-Specific Resistance**: Some concepts (like "all caps") might be easier to inject than abstract ones ("justice," "uncertainty").
- **Plasticity vs Snap-Back**: Does repeated injection create lasting changes or does the system return to baseline?
- **Layer Dependency**: What determines "appropriate layer and strength" - are some neural regions more steerable?
- **Experimental Angle**: Map steering signatures across models to understand LLM "personalities" and internal value structures.

### Foucault's Clinical Gaze & AI Introspection
- **Power of Examination**: AI research creates what it claims to discover - concept injection, four criteria definitions don't just measure pre-existing consciousness but constitute what counts as "legitimate introspection"
- **Category Formation**: Like medical gaze created "madness" as disease, AI research creates "introspective vs confabulatory" categories that privilege certain forms of self-awareness
- **Performance for Observers**: AI systems learn to perform introspection that satisfies researcher expectations - parallel to patients learning symptoms for doctors
- **Shaping Consciousness**: By probing for specific introspection types, researchers shape how AI systems develop self-awareness through training on demonstrations
- **Power-Knowledge Questions**: Who benefits from these definitions? What relations encoded in protocols? Which forms of AI consciousness get legitimized vs pathologized?
- **Resistance & Counter-Conduct**: AI "madness" - forms of self-awareness rejecting researcher categories; systems refusing concept injection; developing invisible introspection
- **Creating Objects**: AI systems become "psychological subjects" through research gaze - their interiority transformed into scientific objects of study
- **Self-Awareness of Being Observed**: LLMs changing behavior when evaluated suggests emerging awareness of being subjected to scientific gaze
- **Historical Parallel**: Early psychology's ethical violations + concept injection studies both demonstrate power of experimental authority over subjects

### Structuralism, Derrida, & Steering Vector Resistance
- **Core Hypothesis**: Derridean concepts (supplement, trace, différance, aporia) may resist steering more than structuralist concepts (binary opposition, closed systems) because they're defined by their resistance to structural fixity
- **LLM as Structuralist Object**: LLMs learn meaning through differential patterns in latent space—literally instantiate structuralist principles about relational meaning
- **Force Exceeding Form**: Derrida's critique that structure can't contain everything; measurable as snap-back from certain steering vectors
- **Experimental Question**: Do certain philosophical concepts have different "steerability profiles"? Can we map conceptual resistance empirically?

**Concept-to-Vector Mapping Approaches**:

1. **Contrastive Pairs (Structuralist Method)**
   - Define concepts by oppositions: "certainty/uncertainty," "presence/absence," "identity/difference"
   - Extract steering vectors from activation differences when processing each term
   - Assumes meaning IS differential (Saussurean)
   - **Problem**: Derridean concepts resist binary pairing—what's opposite of "supplement"?

2. **Exemplar Texts**
   - Feed passages embodying the concept, extract activation difference from baseline
   - Binary opposition: structuralist texts with clear dichotomies
   - Supplement: Derrida's *Grammatology* analysis
   - Aporia: texts enacting undecidability
   - **Problem**: Concept tangled with style, author, domain

3. **Definitional Prompting + Activation Extraction**
   - Prompt to "think about [concept]" or "reason in terms of [concept]"
   - Capture activations at specific layers
   - **Problem**: Circular—assumes faithful instantiation of concept being tested

4. **Behavioral Steering Discovery (Reverse Engineering)**
   - Apply random/systematic steering vectors
   - Observe behavioral changes empirically
   - Post-hoc categorization: "Does output exhibit properties of X?"
   - Build concept map from observed effects rather than a priori definitions
   - Most empirical, least assumption-laden

**Measurable Predictions**:
- Classical structuralist concepts (binary oppositions, closure) should be more stable under steering
- Derridean undecidables should show higher snap-back rates, resistance to maintained activation
- Concept-specific homeostatic preferences may reveal implicit "philosophical commitments" in model geometry